{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Conjunto de entrada\n",
    "X = iris.data[:,2:] # Largura e comprimento da petala\n",
    "y = iris.target\n",
    "\n",
    "# Max_depth = profundidade maxima(Hiperparametro)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2,random_state=42)\n",
    "tree_clf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5,1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5,1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DIA  TEMPO  TEMPERATURA  UMIDADE  VENTO  JOGA\n",
      "0     0      1            2        0      1     0\n",
      "1     6      1            2        0      0     0\n",
      "2     7      2            2        0      1     1\n",
      "3     8      0            1        0      1     1\n",
      "4     9      0            0        1      1     1\n",
      "5    10      0            0        1      0     0\n",
      "6    11      2            0        1      0     1\n",
      "7    12      1            1        0      1     0\n",
      "8    13      1            0        1      1     1\n",
      "9     1      0            1        1      1     0\n",
      "10    2      1            1        1      0     0\n",
      "11    3      2            1        0      0     0\n",
      "12    4      2            2        1      1     0\n",
      "13    5      0            1        0      0     1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('Play.xlsx')\n",
    "\n",
    "# Converte todas as colunas para tipo categórico\n",
    "df_categorical = df.astype('category')\n",
    "\n",
    "# Transforma cada coluna em códigos numéricos\n",
    "df_encoded = df_categorical.apply(lambda x: x.cat.codes)\n",
    "\n",
    "\n",
    "X = df_encoded.iloc[:,[1,2,3,4]]\n",
    "y = df_encoded.iloc[:,[5]] \n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5,random_state=42)\n",
    "tree_clf.fit(X,y)\n",
    "\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[6,1,2,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[6,1,2,0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercicio 3 \n",
    "classificar o conjunto de dados \"moons\"(make moons)\n",
    "a) Dividir entre treino e teste\n",
    "b) Encontrar bons valores de hiperparâmetros para o classificados, utilizando a classe GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Melhor score médio de validação: 0.9994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GERAR DADOS\n",
    "X,y = make_moons(n_samples=10000,random_state=42)\n",
    "\n",
    "#  hiperparemetros para teste\n",
    "param_grid = {\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Treinar modelo\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(tree_clf,param_grid, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor score médio de validação:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4\n",
    "Criar uma floresta, com base no exercício anterior:\n",
    "\n",
    "a)Gerar mil subconjunto do conjunto de treinamento, cada um contendo 100 instâncias selecionadas aleatoriamente. (Dica: usar a classe ShuffleSplit da Scikit-Learn.)\n",
    "\n",
    "b)Treinar uma árvore de decisão em cada subconjunto, usando os melhores valores de hiperparâmetros encontrados no exercício anterior.\n",
    "\n",
    "c)Para cada instância do conjunto de testes, gere as predições das mil árvores de decisão e mantenha somente as predições mais frequentes (Dica, usar a função mode() do SciPy). Essa abordagem fornece as predições dos votos majoritários em relação ao conjunto de testes.\n",
    "\n",
    "d)Avalie essas predições no conjunto de testes: você deve obter uma acurácia um pouco maior do que a do seu primeiro modelo (cerca de 0,5 a 1,5% maior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da floresta (votação majoritária): 0.9915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ss = ShuffleSplit(n_splits=1000, train_size=100, random_state=42)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "floresta = []\n",
    "\n",
    "for train_indices, _ in ss.split(X_train_full):\n",
    "    X_sub = X_train_full[train_indices]\n",
    "    y_sub = y_train_full[train_indices]\n",
    "    \n",
    "    tree_clf = DecisionTreeClassifier(max_depth=5,min_samples_leaf=4,min_samples_split=2, random_state=42)\n",
    "    tree_clf.fit(X_sub, y_sub)\n",
    "    \n",
    "    floresta.append(tree_clf)\n",
    "\n",
    "all_predictions = np.zeros((len(floresta), len(X_test)))\n",
    "\n",
    "for idx, tree in enumerate(floresta):\n",
    "    all_predictions[idx] = tree.predict(X_test)\n",
    "\n",
    "majority_votes, _ = mode(all_predictions, axis=0, keepdims=True)\n",
    "y_pred_forest = majority_votes.flatten()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_forest)\n",
    "print(\"Acurácia da floresta (votação majoritária):\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
